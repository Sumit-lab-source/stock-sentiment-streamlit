# -*- coding: utf-8 -*-
"""sentiment _model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l1suQ4Lel9NFRabA0uCJEn5rSCBGJgzh
"""
pip install nltk
pip install bs4
pip install mathplot
import streamlit as st
from urllib.request import urlopen, Request
from bs4 import BeautifulSoup
import nltk
from nltk.sentiment.vader import SentimentIntensityAnalyzer
import pandas as pd
import matplotlib.pyplot as plt

# Download VADER lexicon
nltk.download('vader_lexicon')

# Set up Streamlit layout
st.set_page_config(layout="wide")
st.title("üìà Stock News Sentiment Dashboard")

# User input for stock tickers
tickers_input = st.text_input("Enter stock tickers (comma-separated):", "AMZN,GEV,META")
tickers = [t.strip().upper() for t in tickers_input.split(",") if t.strip()]

# Fetch and analyze data only if tickers exist
if tickers:
    with st.spinner("Scraping and analyzing news..."):
        finviz_url = 'https://finviz.com/quote.ashx?t='
        news_tables = {}
        parsed_data = []

        for ticker in tickers:
            url = finviz_url + ticker
            req = Request(url=url, headers={'user-agent': 'Mozilla/5.0'})
            try:
                response = urlopen(req)
                html = BeautifulSoup(response, 'html.parser')
                news_table = html.find(id='news-table')
                news_tables[ticker] = news_table

                for row in news_table.find_all('tr'):
                    link = row.find('a')
                    title = link.get_text(strip=True) if link else '[No Title]'
                    date_text = row.td.text.strip()
                    date_data = date_text.split(' ')

                    if len(date_data) == 1:
                        time = date_data[0]
                        date = None
                    else:
                        date = date_data[0]
                        time = date_data[1]

                    parsed_data.append([ticker, date, time, title])
            except Exception as e:
                st.error(f"Failed to fetch news for {ticker}: {e}")

        if parsed_data:
            df = pd.DataFrame(parsed_data, columns=['ticker', 'date', 'time', 'title'])

            # Sentiment analysis
            vader = SentimentIntensityAnalyzer()
            df['compound'] = df['title'].apply(lambda title: vader.polarity_scores(title)['compound'])
            df['date'] = pd.to_datetime(df['date'], errors='coerce').dt.date

            # Display raw data
            with st.expander("üîç View Raw Data"):
                st.dataframe(df)

            # Group and pivot for plotting
            mean_df = df.groupby(['ticker', 'date']).mean(numeric_only=True).reset_index()
            pivot_df = mean_df.pivot(index='date', columns='ticker', values='compound')

            # Plot
            st.subheader("üìä Mean Sentiment Scores by Ticker")
            st.bar_chart(pivot_df)
        else:
            st.warning("No news data could be parsed.")
